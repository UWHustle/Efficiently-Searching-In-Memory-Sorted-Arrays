{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot colors\n",
    "lblue=\"#a6cee3\"\n",
    "blue = \"#1f78b4\"\n",
    "lgreen = \"#b2df8a\"\n",
    "green = \"#33a02c\"\n",
    "black= \"#424242\"\n",
    "\n",
    "\n",
    "from os import path, remove\n",
    "import sys\n",
    "import subprocess\n",
    "from subprocess import call,check_output, DEVNULL\n",
    "from pandas import read_csv\n",
    "from os import path\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def validate_args(datasetSize, distribution, parameter, searchAlgo, recordSizeBytes, nThreads):\n",
    "    if recordSizeBytes not in [8,32,128]:\n",
    "        print(\"The valid record size options are 8,32,128\")\n",
    "        exit()\n",
    "\n",
    "# Adds a experiment to the tsv configuration file. Each experiment described the dataset \n",
    "# that is going to be searched and which search algorithm is going to be used.\n",
    "# Input Args:\n",
    "#             tsvpath: the path of the tsvfile\n",
    "#             datasetSize: number of records of the dataset to be searched\n",
    "#             distribution: distribution of the keys of the dataset to be searched\n",
    "#             parameter:    datasets parameter\n",
    "#             searchAlgo: name of the search algorithm to use\n",
    "#             recordSizeBytes: size of record (key + payload)\n",
    "#             nThreads: number of threads to be used for search\n",
    "def add_to_tsv(tsvpath, datasetSize, distribution, parameter, searchAlgo, recordSizeBytes, nThreads):\n",
    "    validate_args(datasetSize, distribution, parameter,searchAlgo, recordSizeBytes, nThreads)\n",
    "    if not path.exists(tsvpath):\n",
    "        with open(tsvpath, \"w\") as f:\n",
    "            f.write(\"DatasetSize\\tDistribution\\tParameter\\tSearchAlgorithm\\tRecordSizeBytes\\t#threads\\n\")\n",
    "#     if parameter is \"\":\n",
    "#         parameter = parameterMap[distribution]\n",
    "#     distribution = paperToBenchmarkDistributionNames[distribution]\n",
    "    with open(tsvpath, \"a\") as f:\n",
    "        conf = str(datasetSize)+\"\\t\"+ \\\n",
    "               str(distribution)+\"\\t\"+ \\\n",
    "               str(parameter)+\"\\t\"+ \\\n",
    "               str(searchAlgo)+\"\\t\"+ \\\n",
    "               str(recordSizeBytes)+\"\\t\"+ \\\n",
    "               str(nThreads)+\"\\n\"\n",
    "        f.write(conf)\n",
    "    \n",
    "def rm_tsv(tsvpath):\n",
    "    if path.exists(tsvpath):\n",
    "        remove(tsvpath)\n",
    "\n",
    "def UaR_to_tsv(tsvpath, datasetSize, searchAlgo, recordSizeBytes, nThreads, parameter=42):\n",
    "    add_to_tsv(tsvpath, datasetSize, \"uniform\", parameter, searchAlgo, recordSizeBytes, nThreads)\n",
    "    \n",
    "def fbids_to_tsv(tsvpath, searchAlgo, recordSizeBytes, nThreads):\n",
    "    add_to_tsv(tsvpath, 1, \"file\", \"src/datasets/fb/fb-289000.txt\", searchAlgo, recordSizeBytes, nThreads)\n",
    "    \n",
    "def freq1_to_tsv(tsvpath, searchAlgo, recordSizeBytes, nThreads):\n",
    "    add_to_tsv(tsvpath, 1, \"file\", \"src/datasets/wf/wiki.txt\", searchAlgo, recordSizeBytes, nThreads)\n",
    "    \n",
    "def freq2_to_tsv(tsvpath, searchAlgo, recordSizeBytes, nThreads):\n",
    "    add_to_tsv(tsvpath, 1, \"file\", \"src/datasets/wf/newman.txt\", searchAlgo, recordSizeBytes, nThreads)\n",
    "\n",
    "def fal_to_tsv(tsvpath, searchAlgo, recordSizeBytes, nThreads, parameter, datasetSize):\n",
    "    add_to_tsv(tsvpath, datasetSize, \"fal\", parameter, searchAlgo, recordSizeBytes, nThreads)\n",
    "\n",
    "def cfal_to_tsv(tsvpath, searchAlgo, recordSizeBytes, nThreads, parameter, datasetSize):\n",
    "    add_to_tsv(tsvpath, datasetSize, \"cfal\", parameter, searchAlgo, recordSizeBytes, nThreads)\n",
    "\n",
    "def gap_to_tsv(tsvpath, searchAlgo, recordSizeBytes, nThreads, random_seed, shape, datasetSize):\n",
    "    add_to_tsv(tsvpath, datasetSize, \"gap\", str(random_seed)+\",\"+str(shape), searchAlgo, recordSizeBytes, nThreads)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(tsvname):\n",
    "    if not path.exists(\"../searchbench\"):\n",
    "        print(\"Please make sure searchbench is compiled. You can compile this by running make on the parent directory.\")\n",
    "        sys.exit()\n",
    "        \n",
    "    resultFile=tsvname+\".out\"\n",
    "    if path.exists(resultFile):\n",
    "        print(\"This tsv has been already executed and the results have been saved.\")\n",
    "        print(\"If you want to rerun the experiments please delete the file: \"+tsvname+\".out\")\n",
    "    else:\n",
    "        with open(resultFile, \"w\") as log_file:\n",
    "            subprocess.run([\"python3\",\"./getTimes.py\",\"./replicate_experiments/\"+tsvname], stdout=log_file, stderr=DEVNULL, cwd=\"../\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_results(tsvname):\n",
    "    times=[]\n",
    "    with open(tsvname+\".out\", newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in csvreader:\n",
    "            if len(row)>0 and row[0][0].isdigit():\n",
    "                times.append(float(row[0].split()[7]))\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-16-5524e5a377e8>, line 106)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-5524e5a377e8>\"\u001b[0;36m, line \u001b[0;32m106\u001b[0m\n\u001b[0;31m    print(\"Caption: Speedup achieved by Interpolation Search methods over Binary Search on real datasets.\\n\u001b[0m\n\u001b[0m                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "tsv = \"fig2.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "# TODO(faster)\n",
    "size=5 #8\n",
    "for algorithm in [\"bs\", \"sip\", \"is\", \"tip\"]:\n",
    "    UaR_to_tsv(tsv, 10**size, algorithm, 8, 1)\n",
    "    \n",
    "for algorithm in [\"bs\", \"sip\", \"is\", \"tip\"]:\n",
    "    fbids_to_tsv(tsv, algorithm, 8, 1) \n",
    "    \n",
    "for algorithm in [\"bs\", \"tip\"]:\n",
    "    fal_to_tsv(tsv, algorithm, 8, 1, 1.05, 10**size) \n",
    "\n",
    "for algorithm in [\"bs\", \"tip\"]:\n",
    "    freq1_to_tsv(tsv, algorithm, 8, 1)\n",
    "\n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "# print(results)\n",
    "\n",
    "# X: dataset\n",
    "# Y: Speedup with BS\n",
    "\n",
    "uarResults=results[0:4]\n",
    "fbidsResults=results[4:8]\n",
    "falResults=results[8:10]\n",
    "freq1Results=results[10:12]\n",
    "\n",
    "# Calculate speedups of sip, is and tip compard to Binary Search\n",
    "uarSpeedups = []\n",
    "for i in range(1,len(uarResults)):\n",
    "    uarSpeedups.append(uarResults[0]/uarResults[i])\n",
    "\n",
    "fbidsSpeedups = []\n",
    "for i in range(1,len(fbidsResults)):\n",
    "    fbidsSpeedups.append(fbidsResults[0]/fbidsResults[i])\n",
    "\n",
    "falSpeedups = []\n",
    "for i in range(1,len(falResults)):\n",
    "    falSpeedups.append(falResults[0]/falResults[i])\n",
    "    \n",
    "freq1Speedups = []\n",
    "for i in range(1,len(freq1Results)):\n",
    "    freq1Speedups.append(freq1Results[0]/freq1Results[i])\n",
    "\n",
    "    \n",
    "# Plot\n",
    "\n",
    "# Group the speedups of each algorithm\n",
    "tipSpeedups=[uarSpeedups[0], fbidsSpeedups[0], falSpeedups[0], freq1Speedups[0]]\n",
    "ISSpeedups=[uarSpeedups[1], fbidsSpeedups[1],0,0]\n",
    "sipSpeedups=[uarSpeedups[2], fbidsSpeedups[2],0,0]\n",
    "\n",
    "labels=[\"UaR\", \"fb\", \"fal-1.05\", \"wf\"]\n",
    "pos = [0,1,2,3]\n",
    "width = 0.25 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "plt.bar(pos, \n",
    "        tipSpeedups, \n",
    "        width, \n",
    "        alpha=0.5, \n",
    "        color=lblue, \n",
    "        label=\"TIP\") \n",
    "\n",
    "plt.bar([p + width+.02 for p in pos], \n",
    "        ISSpeedups,\n",
    "        width, \n",
    "        alpha=0.5, \n",
    "        color=blue, \n",
    "        label=\"Interpolation Search\",\n",
    "        hatch=\"\\\\\") \n",
    "\n",
    "plt.bar([p + width*2+.04 for p in pos], \n",
    "        sipSpeedups,\n",
    "        width, \n",
    "        alpha=0.5, \n",
    "        color=lgreen, \n",
    "        label=\"SIP\",\n",
    "        hatch=\"-\") \n",
    "\n",
    "plt.plot([-1,5],[1,1],linestyle=\"dashed\", color=black, label=\"BS\")\n",
    "\n",
    "ax.set_ylabel('Speedup', size=18)\n",
    "\n",
    "ax.set_title('Figure 2', size=22)\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(labels, size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "# plt.ylim([0, max(df['pre_score'] + df['mid_score'] + df['post_score'])] )\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['TIP', 'Interpolation Search', 'SIP'], loc='upper right')\n",
    "plt.legend(prop={'size': 15})\n",
    "plt.show()\n",
    "\n",
    "print(\"Caption: Speedup achieved by Interpolation Search methods over Binary Search on real datasets.\\n\\\n",
    "       The first two dataset UaR and fb_ids are uniformly distributed datasets, where as fal-1.05 and freq1\\n\\\n",
    "      are skewed datasets. 8 Byte record are used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algos: i-hyp-64, i-opt-8, bs\n",
    "# datasets: fb\n",
    "# record-size: 8,32,128\n",
    "\n",
    "tsv=\"fig5.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "for recordSize in [8,32,128]:\n",
    "    for algorithm in [\"sip\", \"bs\", \"tip\", \"is\"]:\n",
    "        fbids_to_tsv(tsv, algorithm, recordSize, 1)\n",
    "\n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Record size\n",
    "# Y: Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algos: i-opt-8, bs\n",
    "# datasets: UaR\n",
    "# record-size: 8,32,128\n",
    "    \n",
    "\n",
    "tsv=\"fig6.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "#TODO(faster)\n",
    "for datasetSize in [3,4,5]:#,6,7,8,9]:\n",
    "    for algorithm in [\"bs\", \"sip\"]:\n",
    "        for recordSize in [8,32,128]:\n",
    "            UaR_to_tsv(tsv, 10**datasetSize, algorithm, recordSize, 1)   \n",
    "            \n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Numver of records\n",
    "# Y: Speedup vs bs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algos: i-opt-8, bs\n",
    "# datasets: UaR(10^3 - 10^9)\n",
    "# record-size: 32\n",
    "    \n",
    "tsv=\"fig7.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "#TODO(faster)\n",
    "for datasetSize in [3,4,5]:#,6,7,8,9]:\n",
    "    for algorithm in [\"bs\", \"sip\"]:\n",
    "            UaR_to_tsv(tsv, 10**datasetSize, algorithm, 32, 1)  \n",
    "    \n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Numver of records(log)\n",
    "# Y: times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv8=\"fig8_8.tsv\"\n",
    "tsv32=\"fig8_32.tsv\"\n",
    "tsv128=\"fig8_128.tsv\"\n",
    "rm_tsv(tsv8)\n",
    "rm_tsv(tsv32)\n",
    "rm_tsv(tsv128)\n",
    "\n",
    "#TODO(add iseq)\n",
    "for algorithm in [\"sip\", \"iseq\"]:\n",
    "    for datasetSize in [3,4,5,6,7]:\n",
    "        for gapShape in [0.7,0.9,0.99,0.99999]:\n",
    "               gap_to_tsv(tsv8, algorithm, 8, 1, 47,gapShape, 10**datasetSize)\n",
    "                \n",
    "for algorithm in [\"sip\", \"iseq\"]:\n",
    "    for datasetSize in [3,4,5,6,7]:\n",
    "        for gapShape in [0.7,0.9,0.99,0.99999]:\n",
    "               gap_to_tsv(tsv32, algorithm, 8, 1, 47,gapShape, 10**datasetSize)\n",
    "                \n",
    "for algorithm in [\"sip\", \"iseq\"]:\n",
    "    for datasetSize in [3,4,5,6,7]:\n",
    "        for gapShape in [0.7,0.9,0.99,0.99999]:\n",
    "               gap_to_tsv(tsv128, algorithm, 8, 1, 47,gapShape, 10**datasetSize)\n",
    "            \n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Numver of records\n",
    "# Y: speedup sip vs iseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv=\"fig9.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "#TODO(faster)\n",
    "for algorithm in [\"bs\", \"tip\"]:\n",
    "    for datasetSize in [3,4,5]:#,6,7,8,9]:\n",
    "        for shape in [0.5,1.05,1.25,1.5]:\n",
    "            fal_to_tsv(tsv, algorithm, 8, 1, shape, 10**datasetSize)\n",
    "\n",
    "for algorithm in [\"bs\", \"tip\"]:\n",
    "    for datasetSize in [3,4,5]:#,6,7,8,9]:\n",
    "        for shape in [0.5,1.05,1.25,1.5]:\n",
    "            cfal_to_tsv(tsv, algorithm, 8, 1, shape, 10**datasetSize)\n",
    "\n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Numver of records\n",
    "# Y: times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv=\"fig10.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "#TODO(addiseq)\n",
    "for algorithm in [\"sip\", \"iseq\"]:\n",
    "    for datasetSize in [3,4,5]:\n",
    "        for shape in [0.5,1.05,1.25,1.5]:\n",
    "            fbids_to_tsv(tsv, algorithm, 8, 1)\n",
    "\n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Numver of records(log)\n",
    "# Y: times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv=\"fig11.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "for algorithm in [\"tip\", \"bs\"]:\n",
    "    for recordSize in [8,32,128]:\n",
    "            freq1_to_tsv(tsv, algorithm, recordSize, 1)\n",
    "            \n",
    "for algorithm in [\"tip\", \"bs\"]:\n",
    "    for recordSize in [8,32,128]:\n",
    "            freq2_to_tsv(tsv, algorithm, recordSize, 1)\n",
    "    \n",
    "\n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Numver of records(log)\n",
    "# Y: times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv=\"fig12.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "#TODO(faster)\n",
    "for datasetSize in [3,4,5]:#6,7,8]:\n",
    "        UaR_to_tsv(tsv, 10**datasetSize, \"sip\", 8, 1,42)\n",
    "\n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Numver of records(log)\n",
    "# Y: times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv=\"fig18.tsv\"\n",
    "rm_tsv(tsv)\n",
    "\n",
    "#TODO(faster)\n",
    "for algorithm in [\"bs\", \"sip\"]:\n",
    "    for threads in [2,8,16,32]:\n",
    "        UaR_to_tsv(tsv, 10**4, algorithm, 8, threads,42)\n",
    "#         UaR_to_tsv(tsv, 10**8, \"sip\", 8, threads,42)\n",
    "\n",
    "run(tsv)\n",
    "results=get_results(tsv)\n",
    "print(results)\n",
    "\n",
    "# X: Numver of records(log)\n",
    "# Y: times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
